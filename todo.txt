- Create point wise loss
- Create listwise loss
- Safe the model names to avoid the initial model name colleciton
- Cerate measure of performance saved by using the routers (as in the paper)
- Test long training in other infrastructure (maybe colab)
- Model checkpointing
- Router that balances efficiemcy
- Efficiency score

- Create a table with prompt-model and learn a portfolio- > learn a set of good initial portfolio
- Select the most difficult samples, to use as portfolio for selecting the model
- Create my own dataset


- Code for training LLM routers with Bert
- Code for simple LLM routers using prompt complexity
- Organize datasets. Use human preference or bert score

- Cold start problem:
    Create a model for embedding LLMs: features, performance metrics, graph embeddings.
    * Idea for creating embeddings with performance metrics:
    * NLL on a subset of selected samples, selected by the training data

- predict OOM errors
- Library with differents
    * Datasets
    * Router
    * Performance Score
    * Token Cost 

- https://github.com/Portkey-AI/gateway
- https://www.runpod.io/pricing  : V100 seems to be a good option